Interview 2023:
1. Please tell me about yourself?
      My name is Simon, I have over 9 years in IT with 5years working as a  
      DevOps as DevOps/Cloud/SR/Platform/Kubernetes/Infrastructure Engineer. 
      I have a strong drive for automation, containers and cloud computing.  

2. What kind project are you managing?
     Thanks for the question, in my environment I have managed couple of projects  aimed 
     at achieving:
        Develops, Tests, Builds, qualification, backup  
        deploys & monitors applications 
       Applications are the output from Softwares development 
     including: 
       1. Provisioning and configuring Infrastructures and servers in AWS using  
          terraform, ansible and Jenkins
          pipeline

       2. Building and maintaining automation pipelines with jenkins for application;
          build, test and upload artifacts into nexus using Jenkins CI job
          tools = Jenkins with Git/Github, maven, sonarqube, nexus, Notification 

      3.  Building automation pipelines with jenkins for application deployment
          using Jenkins with tomcat or Jenkins with docker, dockerhub and Kubernetes 

      4.  Runinng Jenkins continuous monitoring jobs using:
          Jenkins with Kubernetes, prometheus and grafana
          Jenkins with Kubernetes, elasticsearch, filebeat and kibana

     5.  My environment is heavy on aws cloud.  
         Cloud
    6.   Security is inherent in our environment. CS = continuous security 

    7. I have written and maintained ansible-playbooks used by our Systems admins  
       for: patching, userMGT, fileMgt, packageMGT. I am  the escalation point if  
        issues arise while running the ansible-playbooks   

  8. In my environment, I manage Java based project.

web: = 54.221.153.174 key29.pem ubuntu
ansible: 3.86.243.51 key29.pem" ec2-user
  sudo useradd ansible  
  sudo yum -y install python3-pip
  sudo apt -y install python3-pip
  pip3 install ansible --user
  
 #create ansible folder under /etc/
 sudo mkdir /etc/ansible
 sudo chown -R ansible:ansible /etc/ansible
 create ansible .cfig file under /etc/ansible
 vi /etc/ansible/ansible.cfg
 https://github.com/ansible/ansible/blob/stable-2.9/examples/ansible.cfg
 #To change ip hosts 
 vi /etc/ansible/hosts
 
  pip3 install boto3 botocore --user
  pip3 install --upgrade requests --user
appserver: 
  44.204.71.5 class30key.pem" ec2-user
jenkins: 3.223.191.159 class30key.pem" ec2-user


terraform: 54.82.118.56  key29.pem" ubuntu
 sh tf.sh 
 #!/bin/bash
# install terraform in ubuntu server
sudo hostnamectl set-hostname tf
sudo apt install wget unzip -y
wget https://releases.hashicorp.com/terraform/0.12.26/terraform_0.12.26_linux_amd64.zip
sudo unzip terraform_0.12.26_linux_amd64.zip -d /usr/local/bin/
Export terraform binary path temporally
export PATH=$PATH:/usr/local/bin
#Add path permanently for current user.By Exporting path in 
#.bashrc file at end of file.
 echo  "export PATH=$PATH:/usr/local/bin" >> ~/.bashrc
# Source .bashrc to reflect for current session
 source ~/.bashrc
 terraform -version
==================================================


OPERATORS:
  nginx-ingress --- ALB/ELB    
  serviceMesh and Istio 
  Metric-server

10 micro service enterprise applications
11 micro-services per application  
   110 --- 10 pods  = 1100 pods/containers
   
   jenkins initial password: 2106c7ee1cec4fd9a438781ffbadbfd0
   
   MD - Dec 7, 2022
   Running-notes
   
   Patience

Dozie
Position  = Azure DevOps/ES Engineer   
====================================
1. How can you deploy 5m files to 500 servers using IaaC  
       Any Cloud = Terraform/ansible/
       AWS - CloudFormation & System Manager  
       AZURE - Resource manager 
       GCP - Google Cloud Resource
  dbservers 
  file
  In my env, I used ansible or terraform for file migration. 
  We can create an archive for the file, then we unzip the file with the help of ansible, we deploy to the target host.
  I would create ansible-playbook to migrate the file.

  ansible dbservers -m copy -a "src=tesla.zip dest=/opt" -b 
  
- hosts: localhost  
  tasks:
  - name: install package
    package:
      name: ['zip', 'tree', 'nano', 'unzip', 'wget']
      state: latest
  - name: copy file 
    shell: cp *  tesla/ 
    ignore_errors: true
  - name: create archive 
    shell: zip tesla tesla.zip 
    ignore_errors: true
- hosts: web  
  tasks:
  - name: copy files 
    copy: 
      src: tesla.zip 
      dest: /opt/ 

b) they went straight to the role - no time for morning devotion 
c) What are your experiences with elasticsearch?
      
https://www.elastic.co/elasticsearch
Elasticsearch is the world’s leading free and open search and analytics solution. With an emphasis on speed, scale, and relevance it's transforming how the world uses data.

Elasticsearch is a distributed, RESTful search and analytics engine capable of addressing a growing number of use cases. As the heart of the Elastic Stack, it centrally stores your data for lightning fast search, fine‑tuned relevancy, and powerful analytics that scale with ease.
-In our env, we use elasticsearch filebeat and kibana for data analytic and log management. Elasticsearch come with DB, and I deploy it in my env as statefullSet.
Elasticsearch would help to analyse how the app is behaving.Elasticsearch would scrap the logs and does log management, analytic, indexing and with the help
of kibana we can visualize what is happening.
  amazon.com 
  google.com = i9 laptop  

d) How would you deploy 5m files to 500 servers using IAAC?
e) How would these files get to ElasticSearch

f) How does your company access elasticsearch on the browser?
In our env, we're deploying elasticsearch as k8s object, and we're using kibana to visualize what is happening inside.

g) How do you secure your k8s cluster? 
     namespaces: I can restrict access to certain namespaces, example:Developer do not have access to production namespace.
     RBAC [  ]:
        users / groups / ServiceAccounts
        Role/RoleBinding  
        ClusterRole / ClusterRoleBinding  
     IAM 
     resourceQuota to determine how much resources can be consume by a particular namespace.

h) What files do you see in your helm chart?
      -(file)= values.yml[deploy, pvc, ClusterIP, SA, R/RB, CR,CRB, HPA, ingress ] / 
      -(directory)= template/deploy.yml, hpa.yml, sa.yml, rbac.yml, ingress.yml, service.yml 
      
I) what commands exist in your dockerfile?
   	-FROM used to choose my based image which should have my app dependencies
   	-MAINTAINER who have have access to the docker file should know it maintain by us
   	-ADD use to copy file from docker host server to container while creating the image; use also to copy file from external URL.
   	-COPY copy file from docker host server to the container while creating the image
   	-RUN use to execute command while creating the docker image; it is important that we minimize our run instructions so that we can create light weigh images
   	-EXPOSE use to state the port that our container would listening on 
   	-USER tomcat by default docker run on root; if we want to change the user that would manage our containerization we should state with USER.   
   	-VOLUME if we're creating docker file to deploy statefull app we need to create a volume to determine where our data would be mountain in the container
   	-WORDIR  /usr/local/tomcat is where the entire task would be running
   	-ENV pass env variables
   	-LABELS
   	-CMD executed while creating and starting container
   	-ARG
   	-ENTRYPOINT executed while creating and starting container
      
   j) How do you secure your k8s cluster and network?
   When we deploy app, we restrict who can have access using namespace.
   
   i) What Azure/aws tool do you secure your network with?
   To secure our network in aws, we have vpc, subnet concept[private and public], network access control list[nacl], security group waf, iam
   
   k) walk me through your terraform steps in creating a resource.
   In our env provisionning any resource with terraform, we have modules in our env. For example if I have to deploy vpc in azure or aws,
   we have a module which is going to deploy ec2 instance; I have to check the module for any information and in our env it is done in our variable.tf file.
   I have module for most of my deployment and make sure that terraform has the permission to manage and create resources so the right IAM permission is assign, then
   I go through my terraform work flow, I would run terraform init to initialize the backend and to download all the provider plugins, terraform format to organize
   terraform and tf file, terraform validate to make sure the syntax are ok, terraform plan to see the resources that would be created, terraform apply to provisione
   the resources.
   
   L) Have you used azure code pipeline?
   I have not used azure code pipeline, but in aws I use similar resource aws code pipeline 
   
   M) How do you write a groovy custom line in your declarative pipeline in jenkins?
   In groovy, I generally use a jinja bracket.{}
   
   N) Have you used multi stage docker file before?
   

 docker exec myapp pwd 

       azure  / aws /  private  
IaaC   RM      CF      vagrant  
======================================================
Dec 7, 2022
===============
        Tesla 
Taboh
1. Tell us about yourself 
2. Which technologies have you used in your environment
3. Explain how you apply terraform in your env't
4. What problems have you encountered applying terraform 
   in your env't. 
   permissions/syntax/plugins/wrong version/ 
   hardcoded values /regions-specification/attaching keys
   variables: maps/lists/interger/strings/

   Taboh = accessKey/secretAccessKey[EKS EC2READACCESS]

AMI-id ubuntu:
             us-east-1   us-east-2  us-west-1  

terraform_1.4.0-alpha20221109
terraform_1.3.6
terraform_1.3.5
terraform_1.3.4
terraform_1.2.4
terraform_1.2.3
terraform_0.1.9

5. Explain a project you did which you are proud of??

6. What are you your greatest achievements as a DevOps Engineer

 maven / sonarqube /nexus

Jenkins - kubernetes / 
Jenkins - ansible / 
Jenkins - docker / 
Jenkins - terraform /

Jenkins master slave architecture:



have the best env't 
my little experience 
Details  

======================================================================
Dec 8, 2022                                                       ====:
======================================================================
Explain a project you currently manage  

Explain a problem you faced in your project recently
   deprecated helm chart
       custom helm charts  

       3rd party helm charts
   
    helm install myapp app/app
        values.yml  template/deploy.yml service.yml ingress.yml hpa.yml sa.yml rbac.yml 
        helm repo update   
   kubernetes version = 1.25 / 1.10 / 1.15 1.20[docker]
   deprecated apiVersion vs kubectlVersion kubeletVersion  
   docker deprecated
      nodes[kubelet/kubeproxy/container-runtime=container-D/]
   expired token []
   Authentication [kube/config, rbac, ]:
       developer [ Role/RoleBinding ClusterRole/ClusterRoleBinding] 
       Role
   image=Tag/wrongRepo
   scaling issues
   Users could not access the application
   insufficient resources on nodes
   syntax
   Pod crashing
   service not routing traffic to application
kubectl apply -f app.yml  
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ingress-resource-1
spec:
  ingressClassName: nginx
  rules:
  - host: springboot.example.com
    http:
      paths:
      # Default Path(/)
      - backend:
          serviceName: springboot
          servicePort: 80
      - path: /java-web-app
        backend:
          serviceName: javawebapp
          servicePort: 80 
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["pods"]
  verbs: ["get", "watch", "list", "create","delete", "describe"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: superadmin
rules:
- apiGroups: ["*"] # "" indicates the core API group
  resources: ["*"]
  verbs: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
# You can specify more than one "subject"
- kind: User
  name: john # "name" is case sensitive
  apiGroup: rbac.authorization.k8s.io
- kind: Group
  name: managers # "name" is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  # "roleRef" specifies the binding to a Role / ClusterRole
  kind: Role #this must be Role or ClusterRole
  name: superadmin # this must match the name of the Role or ClusterRole you wish to bind to
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
# This role binding allows "jane" to read pods in the "default" namespace.
# You need to already have a Role named "pod-reader" in that namespace.
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
# You can specify more than one "subject"
- kind: User
  name: jane # "name" is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  # "roleRef" specifies the binding to a Role / ClusterRole
  kind: Role #this must be Role or ClusterRole
  name: pod-reader # this must match the name of the Role or ClusterRole you wish to bind to
  apiGroup: rbac.authorization.k8s.io




   
